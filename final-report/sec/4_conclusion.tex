\section{Conclusion}
\label{sec:conclusion}

This project presents a modular, Python-based JPEG-like image compression system developed for EECE 5698: Visual Sensing and Computing. Our implementation emulates the classical JPEG compression pipeline while introducing key enhancements to promote experimentation and flexibility. By decoupling pipeline stages and supporting parameterized configuration files, our system allows users to explore the impact of various compression strategies (including downsampling factors, block sizes, and quantization levels) on image quality and file size.

We implemented every core stage of the compression and decompression workflow, including color space conversion, block-based DCT, configurable quantization, entropy encoding via a custom Huffman implementation, and a full-featured decompression pipeline. Throughout development, we prioritized technical rigor and reproducibility, carefully handling edge cases such as padding, alignment, and raw image format compatibility (e.g., Canon CR2). All major system parameters are exposed via YAML configuration files, which enable both one-off experiments and automated parameter sweeps. Supporting scripts like \texttt{results\_compression.py}, \texttt{parameter\_sweeps.py}, and \texttt{results\_decompression.py} were developed to streamline batch testing and metrics collection.

Using this flexible framework, we are able to determine the relative sensitivity of various performance metrics for both compression quality and semantic preservation to the compression parameters that we exposed with our configurable pipeline. We showed that by far the most effective way to reduce image size while preserving quality and semantic information is through a well chosen set of quantization parameters. However, it is critical that the Luminance and Chrominance channels are quantized on the same order of magnitude in order for semantic information to be preserved. Other compression parameters are not as effective in reducing image size while maintaining quality, although the ability to modify these parameters allows for an opportunity to perform deeper optimizations.

Beyond implementation fidelity, the system’s architecture serves as a useful sandbox for exploring compression tradeoffs. Unlike most off-the-shelf JPEG implementations, our system exposes every internal stage, allowing students and researchers to tune, visualize, and analyze the consequences of individual design decisions. This modularity makes it well-suited for further experimentation, including the integration of alternative transforms (e.g., wavelets), advanced quantization techniques, or perceptual encoding strategies such as saliency-aware masking.

Despite its strengths, the system has limitations. 
While sufficient for academic exploration, it is not optimized for real-time performance or production-scale workloads. While our implemnetation of image-specific huffman tables leads to a higher compression rate than pre-computed tables, the computational complexity of computing huffman tables in real time makes this approach impractical. Error resilience and fault tolerance are minimal, and certain test images (especially large or atypically dimensioned files) may reveal edge case bugs. These limitations point to several promising areas for future work, such as:

\begin{itemize}
    \item \textbf{Hybrid Huffman tables} Selecting Huffman tables from a pre-computed set with minimal overhead at time of compression, while keeping some of the gains of having image-specific tables.
    \item \textbf{Advanced entropy coding} (e.g., arithmetic coding or context modeling)
    \item \textbf{Integration of perceptual metrics or machine learning-based tuning}
    \item \textbf{Visualization tools} for examining intermediate DCT coefficients, zigzag orderings, or compression artifacts
    \item \textbf{Different Color Transformations} to better preseve semantic information when quantizing images. Results suggest that there is dependance on both Luminance and Chrominance channels to encode semantic meaning, so applying a transformation that more consisly represents this information could improve the compressions performance.
\end{itemize}

In conclusion, our JPEG-like image compression system fulfills the project’s objectives and provides a valuable learning tool for understanding and exploring lossy image compression. Through collaborative development and structured testing, we delivered a working pipeline that balances classical compression principles~\cite{jpegOverview2025} with modern engineering flexibility. We hope that future students, researchers, or contributors will build upon this foundation to explore more advanced or novel compression techniques. Our work reinforces the importance of foundational compression research~\cite{haines1992compression} in shaping modern approaches and inspiring hands-on educational implementations.
All source code, configuration files, and relative files used in this project are available at: \url{https://github.com/Roude/EECE5698-image-compression-roud-drag-elar}.